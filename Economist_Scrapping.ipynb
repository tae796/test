{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63efc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import urllib.request\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus          \n",
    "import time\n",
    "from urllib.request import (urlopen, urlparse, urlunparse, urlretrieve)\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import math\n",
    "import re\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import os \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import os\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import traceback         \n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb43edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-setuid-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument('--ignore-certificate-errors')\n",
    "chrome_options.add_argument('--allow-running-insecure-content')\n",
    "chrome_options.add_argument(\"disable-infobars\")\n",
    "#chrome_options.add_argument(\"headless\")\n",
    "#chrome_options.add_argument(\"--start-maximized\")\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "os.environ['WDM_LOG'] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "chrome_path = 'C:\\\\Users\\\\cafel\\\\chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09e0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_scroll_down(driver):\n",
    "    SCROLL_PAUSE_SEC = 3\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "  \n",
    "        if new_height == last_height:\n",
    "            return 1\n",
    "        last_height = new_height\n",
    "\n",
    "def get_driver(chrome_path, chrome_options, url):\n",
    "    driver = None\n",
    "    count = 0\n",
    "    \n",
    "    while driver is None and count < 10:\n",
    "        try:\n",
    "            driver = webdriver.Chrome(chrome_path, options=chrome_options)\n",
    "        except Exception as e:\n",
    "            count += 1\n",
    "            print(f\"Error creating driver: {e}\")\n",
    "            clean_up(driver)\n",
    "            continue\n",
    "    \n",
    "    connect = False\n",
    "    \n",
    "    while not connect: \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(10)\n",
    "            connect = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to URL: {e}\")\n",
    "            clean_up(driver)\n",
    "            driver = webdriver.Chrome(chrome_path, options = chrome_options)\n",
    "\n",
    "    return driver\n",
    "\n",
    "def clean_up(driver):\n",
    "    # Define your clean-up logic here\n",
    "    pass\n",
    "\n",
    "def reset_driver(driver, chrome_path, chrome_options, url):\n",
    "    try:\n",
    "        driver.quit()\n",
    "        driver = get_driver(chrome_path, chrome_options, url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error resetting driver: {e}\")\n",
    "        driver = get_driver(chrome_path, chrome_options, url)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def write_data(write_file, datas):\n",
    "    for data in datas:\n",
    "        write_file = write_file.append(data, ignore_index=True)\n",
    "    \n",
    "    return write_file\n",
    "\n",
    "def get_list(chrome_path, chrome_options):\n",
    "    total = pd.DataFrame()\n",
    "\n",
    "    for i in range(600, 650):\n",
    "        base_url = 'https://www.economist.com/finance-and-economics?page={}'.format(i)\n",
    "        try:\n",
    "            driver = get_driver(chrome_path, chrome_options, base_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating driver: {e}\")\n",
    "            continue  # Skip to the next iteration on error\n",
    "        \n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        try:\n",
    "            # Handle iFrame\n",
    "            iframe = driver.find_element(By.CSS_SELECTOR, \"#sp_message_iframe_921614\")\n",
    "            driver.switch_to.frame(iframe)\n",
    "            driver.find_element(By.CSS_SELECTOR, '#notice > div.message-component.message-row.teg-stackable.teg-footer > div.message-component.message-column.teg-stackable--accept > button').click()\n",
    "            \n",
    "            page_exist = True\n",
    "            datas = []\n",
    "\n",
    "            while page_exist:\n",
    "                try:\n",
    "                    main = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'section-collection.section-collection--finance-and-economics.ds-layout-grid.ds-layout-grid--edged'))).find_element(By.CLASS_NAME, 'layout-section-collection.ds-layout-grid')\n",
    "                    articles = main.find_elements(By.CLASS_NAME, 'css-e6sfh4.e1mdktgm0')\n",
    "\n",
    "                    for article in tqdm(articles):\n",
    "                        data = {}\n",
    "                        try:\n",
    "                            url = article.find_element(By.CSS_SELECTOR, 'div > h3 > a').get_attribute('href')\n",
    "                        except Exception:\n",
    "                            url = None\n",
    "\n",
    "                        data['url'] = url\n",
    "                        datas.append(data)\n",
    "\n",
    "                    page_exist = False\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping data: {e}\")\n",
    "                    break\n",
    "\n",
    "        finally:\n",
    "            driver.close()\n",
    "\n",
    "        dataframe = pd.DataFrame(datas)\n",
    "        total = pd.concat([total, dataframe])\n",
    "\n",
    "    total = total.drop_duplicates(subset=['url'], keep='first')\n",
    "    total.to_csv('C:/Users/cafel/Desktop/The_Economist/article_url_total_2.csv', encoding='utf-8-sig', index=False)\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e336570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 119.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "get_list(chrome_path, chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4120178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = pd.read_csv('C:/Users/cafel/Desktop/The_Economist/article_url_total_1.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9679ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(chrome_path, chrome_options, url_list):\n",
    "    login_url = 'https://myaccount.economist.com/s/login/'\n",
    "    username = 'cafelate789@gmail.com'\n",
    "    password = 'tea@250803'\n",
    "    \n",
    "    # Set up the Chrome driver\n",
    "    driver = webdriver.Chrome(chrome_path, options=chrome_options)\n",
    "    driver.get(login_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Find the login elements and input credentials\n",
    "    username_input = driver.find_element(By.XPATH, '//*[@id=\"input-6\"]')\n",
    "    password_input = driver.find_element(By.XPATH, '//*[@id=\"input-8\"]')\n",
    "    submit_button = driver.find_element(By.XPATH, '/html/body/div[3]/div[3]/div[1]/div/div/div/div[2]/div/div/c-lwc-login-form/div/lightning-card/article/div[2]/slot/div[2]/div[5]/lightning-button/button')\n",
    "\n",
    "    username_input.send_keys(username)\n",
    "    password_input.send_keys(password)\n",
    "    submit_button.click()\n",
    "\n",
    "    # Wait for the login process to complete\n",
    "    WebDriverWait(driver, 10).until(EC.url_changes(login_url))\n",
    "\n",
    "    total = pd.DataFrame()\n",
    "\n",
    "    for i in tqdm(range(len(url_list))):\n",
    "        scrapping_url = url_list['url'][i]\n",
    "        driver.get(scrapping_url)\n",
    "        \n",
    "        try:          \n",
    "            page_exist = True\n",
    "            datas = []\n",
    "            \n",
    "            try:\n",
    "                # Handle iFrame\n",
    "                iframe = driver.find_element(By.CSS_SELECTOR, \"#sp_message_iframe_921614\")\n",
    "                driver.switch_to.frame(iframe)\n",
    "                driver.find_element(By.CSS_SELECTOR, '#notice > div.message-component.message-row.teg-stackable.teg-footer > div.message-component.message-column.teg-stackable--accept > button').click()\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            while page_exist:\n",
    "                try:\n",
    "                    selenium_scroll_down(driver)\n",
    "                    main = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'css-9rt3sc.e10tor440'))).find_element(By.CLASS_NAME, 'css-1bfdg3q.e1pkqesp0')\n",
    "                    paragraphs = main.find_elements(By.CLASS_NAME, 'css-1hno3qs.e190yofl0')\n",
    "                    try:\n",
    "                        date_text = main.find_element(By.CSS_SELECTOR, 'div.css-1qjp74c.e8tkvfk0 > div:nth-child(3) > div > div.css-1fiks87.e1rnrkkh0 > div > div > div:nth-child(1) > time').get_attribute('datetime')[:10]\n",
    "                        date = datetime.strptime(date_text, '%Y-%m-%d')\n",
    "                        title = main.find_element(By.CSS_SELECTOR, 'div.css-1qjp74c.e8tkvfk0 > div:nth-child(1) > section > h1').text\n",
    "                    except:\n",
    "                        date = None\n",
    "                        title = None\n",
    "                    \n",
    "                    data = {'date': date, 'title': title}\n",
    "                    datas.append(data)\n",
    "\n",
    "                    page_exist = False\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping data: {e}\")\n",
    "                    break\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        dataframe = pd.DataFrame(datas)\n",
    "        total = pd.concat([total, dataframe])\n",
    "\n",
    "    total.to_csv('C:/Users/cafel/Desktop/The_Economist/article.csv', encoding='utf-8-sig', index=False)\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397bec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:21<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "get_article(chrome_path, chrome_options, url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd7ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(chrome_path, chrome_options, url_list):\n",
    "    login_url = 'https://myaccount.economist.com/s/login'\n",
    "    username = 'cafelate789@gmail.com'\n",
    "    password = 'tea@250803'\n",
    "    \n",
    "    # 세션 생성\n",
    "    session = requests.Session()\n",
    "\n",
    "    # 로그인 요청을 위한 데이터\n",
    "    login_data = {\n",
    "        'username': username,\n",
    "        'password': password\n",
    "    }\n",
    "    \n",
    "    # 로그인 요청\n",
    "    login_response = session.post(login_url, data = login_data)\n",
    "    \n",
    "    if login_response.status_code == 200:\n",
    "        print('로그인 성공')\n",
    "    else:\n",
    "        print('로그인 실패')\n",
    "        \n",
    "    time.sleep(5)\n",
    "        \n",
    "    total = pd.DataFrame()\n",
    "\n",
    "    for i in tqdm(range(len(url_list))):\n",
    "        scrapping_url = url_list['url'][i]\n",
    "        scraping_response = session.get(scrapping_url)\n",
    "        \n",
    "        try:          \n",
    "            page_exist = True\n",
    "            datas = []\n",
    "\n",
    "            while page_exist:\n",
    "                try:\n",
    "                    selenium_scroll_down(driver)\n",
    "                    main = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'css-9rt3sc.e10tor440'))).find_element(By.CLASS_NAME, 'css-1bfdg3q e1pkqesp0')\n",
    "                    paragraphs = main.find_elements(By.CLASS_NAME, 'css-1hno3qs.e190yofl0')\n",
    "                    try:\n",
    "                        date_text = main.find_element(By.CSS_SELECTOR, 'div.css-1qjp74c.e8tkvfk0 > div:nth-child(3) > div > div.css-1fiks87.e1rnrkkh0 > div > div > div:nth-child(1) > time').get_attribute('datetime').text[:10]\n",
    "                        print(date_text)\n",
    "                        date = datetime.strptime(date_text, '%Y-%m-%d')\n",
    "                        title = main.find_element(BY.CSS_SELCTOR, 'div.css-1qjp74c.e8tkvfk0 > div:nth-child(1) > section > h1').text\n",
    "                        print(title)\n",
    "                    except:\n",
    "                        date = None\n",
    "                        title = None\n",
    "                    \n",
    "                    data['date'] = date\n",
    "                    data['title'] = title\n",
    "                    datas.append(data)\n",
    "\n",
    "                    page_exist = False\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping data: {e}\")\n",
    "                    break\n",
    "\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "        dataframe = pd.DataFrame(datas)\n",
    "        total = pd.concat([total, dataframe])\n",
    "\n",
    "    total = total.drop_duplicates(subset=['url'], keep='first')\n",
    "    total.to_csv('C:/Users/cafel/Desktop/The_Economist/article.csv', encoding='utf-8-sig', index=False)\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7415d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
